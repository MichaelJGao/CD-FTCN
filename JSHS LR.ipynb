{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81c7e50-0ec7-40eb-9a3a-e4d3a2803e3e",
   "metadata": {},
   "source": [
    "# LR\n",
    "In this notebook, I provide a sample implementation of the LR model for comparative analysis. Spectra are first obtained from files in the \"dataset\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba100029-437e-4f26-9655-282a961fa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d89cc32-c167-4826-8e90-4cd2b7b2f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_and_preprocess(train_file, val_file):\n",
    "    \"\"\"Load and preprocess training and validation data.\"\"\"\n",
    "    train_df = pd.read_csv(train_file, header=None)\n",
    "    val_df = pd.read_csv(val_file, header=None)\n",
    "    \n",
    "    # Extract samples and labels\n",
    "    train_samples = train_df.iloc[1:-1, 1:].values.astype(float)\n",
    "    train_labels = train_df.iloc[-1, 1:].values.astype(float)\n",
    "    val_samples = val_df.iloc[1:-1, 1:].values.astype(float)\n",
    "    val_labels = val_df.iloc[-1, 1:].values.astype(float)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    train_samples = scaler.fit_transform(train_samples.T).T\n",
    "    val_samples = scaler.transform(val_samples.T).T\n",
    "    \n",
    "    return train_samples, train_labels, val_samples, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d772268-830d-415c-b78e-c383f541d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model 30 times across all seeds\n",
    "all_metrics = []\n",
    "conf_matrices = []\n",
    "\n",
    "for seed_index in range(30):\n",
    "    print(f\"Seed {seed_index+1}/30\")\n",
    "\n",
    "    # Load and preprocess data\n",
    "    train_file = f\"../No_MSC/Seed_{seed_index}/Combined_Train.csv\"\n",
    "    val_file = f\"../No_MSC/Seed_{seed_index}/Combined_Validation.csv\"\n",
    "    train_samples, train_labels, val_samples, val_labels = load_and_preprocess(train_file, val_file)\n",
    "    \n",
    "    # Prepare data for Logistic Regression\n",
    "    X_train = train_samples.T\n",
    "    y_train = train_labels\n",
    "    X_val = val_samples.T\n",
    "    y_val = val_labels\n",
    "\n",
    "    # Define and train Logistic Regression model\n",
    "    model = LogisticRegression(random_state=seed_index, max_iter=10000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_pred)\n",
    "    val_precision = precision_score(y_val, y_pred)\n",
    "    val_recall = recall_score(y_val, y_pred)\n",
    "    val_f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    # Store metrics and confusion matrix\n",
    "    all_metrics.append((val_accuracy, val_precision, val_recall, val_f1))\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    conf_matrices.append(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c78e8-9132-46ba-87ab-39917b4c1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the metrics to a DataFrame for easier plotting\n",
    "metrics_df = pd.DataFrame(all_metrics, columns=['val_accuracy', 'val_precision', 'val_recall', 'val_f1'])\n",
    "\n",
    "# Plot the box plots for each metric\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Box plot for validation accuracy\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(y=metrics_df['val_accuracy'])\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Accuracy')\n",
    "mean_val = metrics_df['val_accuracy'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Box plot for validation precision\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(y=metrics_df['val_precision'])\n",
    "plt.title('Validation Precision')\n",
    "plt.xlabel('Precision')\n",
    "mean_val = metrics_df['val_precision'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Box plot for validation recall\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(y=metrics_df['val_recall'])\n",
    "plt.title('Validation Recall')\n",
    "plt.xlabel('Recall')\n",
    "mean_val = metrics_df['val_recall'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Box plot for validation F1 score\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(y=metrics_df['val_f1'])\n",
    "plt.title('Validation F1 Score')\n",
    "plt.xlabel('F1 Score')\n",
    "mean_val = metrics_df['val_f1'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Adjust layout and show plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6a077-a0dd-4344-83eb-8b5b39722ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics for later comparison\n",
    "metrics_df.to_csv(\"cenMetrics/LogisticRegression_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9cdfb-33f7-49d3-ae0d-d62955661be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion matrices for each seed\n",
    "for i, conf_matrix in enumerate(conf_matrices):\n",
    "    print(f\"Confusion Matrix for Seed {i+1}:\\n{conf_matrix}\\n\")\n",
    "\n",
    "print(\"Finished Cross-Validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

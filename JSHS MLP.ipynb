{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481749d9-01bd-477e-b30f-671906086e03",
   "metadata": {},
   "source": [
    "# Lee et al. Multilayer Perceptron\n",
    "In this notebook, I provide an implementation of the multilayer perceptron (MLP) proposed by Lee et al. (Lee et al., 2022) in a federated enviroment. Note the proposed MLP is altered for for the purpose of binary sequence-to-label classification; corresponding comments detail all adjustments. The spectra data are first obtained from all files in the \"dataset\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46853c-501a-4f43-9f6d-a9c075dc51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import flwr as fl\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from typing import Optional\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set logging level to critical to reduce output noise\n",
    "logging.getLogger(\"flwr\").setLevel(logging.CRITICAL)\n",
    "\n",
    "# Define device for computation (GPU if available, else CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLIENTS = 5  # Number of federated clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee4264-47d3-46b2-8db2-b803fd823aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_and_preprocess(train_file, val_file):\n",
    "    \"\"\"\n",
    "    Load and preprocess the data from CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        train_file (str): Path to the training CSV file.\n",
    "        val_file (str): Path to the validation CSV file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing training samples, training labels, validation samples, and validation labels.\n",
    "    \"\"\"\n",
    "    # Read the data from CSV files\n",
    "    train_df = pd.read_csv(train_file, header=None)\n",
    "    val_df = pd.read_csv(val_file, header=None)\n",
    "    \n",
    "    # Extract samples and labels, convert them to float\n",
    "    train_samples = train_df.iloc[1:-1, 1:].values.astype(float)\n",
    "    train_labels = train_df.iloc[-1, 1:].values.astype(float)\n",
    "    val_samples = val_df.iloc[1:-1, 1:].values.astype(float)\n",
    "    val_labels = val_df.iloc[-1, 1:].values.astype(float)\n",
    "    \n",
    "    # Standardize the samples\n",
    "    scaler = StandardScaler()\n",
    "    train_samples = scaler.fit_transform(train_samples.T).T\n",
    "    val_samples = scaler.transform(val_samples.T).T\n",
    "    \n",
    "    return train_samples, train_labels, val_samples, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f0ef0-4f44-4a15-8c8e-05c253826212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # Activation function for output layer\n",
    "        self.dropout = nn.Dropout(p=0.3)  # Dropout layer for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2f1ff0-c264-412c-a60e-37d2416e660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping criteria\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Initialize the early stopping mechanism.\n",
    "\n",
    "        Parameters:\n",
    "            patience (int): Number of epochs to wait for improvement before stopping.\n",
    "            min_delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        \"\"\"\n",
    "        Check if training should stop based on validation loss.\n",
    "\n",
    "        Parameters:\n",
    "            val_loss (float): Current validation loss.\n",
    "        \"\"\"\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8413d53-b5fc-4a3e-a883-973a907b101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning utility functions\n",
    "\n",
    "def get_client_parameters(net) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract model parameters for federated learning.\n",
    "\n",
    "    Parameters:\n",
    "        net (nn.Module): The neural network model.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: Model parameters.\n",
    "    \"\"\"\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_client_parameters(net, parameters: List[np.ndarray]):\n",
    "    \"\"\"\n",
    "    Set model parameters for federated learning.\n",
    "\n",
    "    Parameters:\n",
    "        net (nn.Module): The neural network model.\n",
    "        parameters (List[np.ndarray]): List of model parameters.\n",
    "    \"\"\"\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81801d36-116a-4066-8562-e8875a62e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the client model\n",
    "def test_client_model(net, testloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "        net (nn.Module): The neural network model.\n",
    "        testloader (DataLoader): DataLoader for the test set.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing loss, accuracy, precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    # Disable gradient calculation for inference\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(inputs).squeeze()\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            preds = torch.sigmoid(outputs) > 0.5  # Apply sigmoid to get probabilities\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888d498-f7db-41ec-9850-0b9c45a9ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the client model\n",
    "def train_client_model(net, trainloader, valloader, epochs: int, patience: int = 5, client_id: int = 0):\n",
    "    \"\"\"\n",
    "    Train the model on the client's local dataset.\n",
    "\n",
    "    Parameters:\n",
    "        net (nn.Module): The neural network model.\n",
    "        trainloader (DataLoader): DataLoader for the training set.\n",
    "        valloader (DataLoader): DataLoader for the validation set.\n",
    "        epochs (int): Number of training epochs.\n",
    "        patience (int): Patience for early stopping.\n",
    "        client_id (int): Identifier for the client.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        net.train()  # Set model to training mode\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        val_loss, val_accuracy, _, _, _ = test_client_model(net, valloader)\n",
    "        print(f\"Epoch {epoch+1}: val loss {val_loss:.4f}, val accuracy {val_accuracy:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(net.state_dict(), f\"best_model_client_{client_id}.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Stop training if 100% accuracy is achieved\n",
    "        if val_accuracy == 1.0:\n",
    "            print(f\"Early stopping at epoch due to reaching 100% accuracy\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db296c-1594-494a-ab88-cad3f455558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the FlowerClient class for federated learning\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        \"\"\"\n",
    "        Initialize a federated learning client.\n",
    "\n",
    "        Parameters:\n",
    "            cid (int): Client ID.\n",
    "            net (nn.Module): The neural network model.\n",
    "            trainloader (DataLoader): DataLoader for the training set.\n",
    "            valloader (DataLoader): DataLoader for the validation set.\n",
    "        \"\"\"\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Return the model parameters.\"\"\"\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_client_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train the model on local data.\"\"\"\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_client_parameters(self.net, parameters)\n",
    "        train_client_model(self.net, self.trainloader, self.valloader, epochs=20, patience=5, client_id=self.cid)\n",
    "        return get_client_parameters(self.net), len(self.trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate the model on local validation data.\"\"\"\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        # Set the model parameters with the latest global parameters\n",
    "        set_client_parameters(self.net, parameters)\n",
    "        # Evaluate the model\n",
    "        loss, accuracy, precision, recall, f1 = test_client_model(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader.dataset), {\n",
    "            \"accuracy\": float(accuracy),\n",
    "            \"precision\": float(precision),\n",
    "            \"recall\": float(recall),\n",
    "            \"f1\": float(f1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da1533-9eb0-4d50-895d-eb8c8d2f2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Flower client\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    \"\"\"\n",
    "    Create and initialize a FlowerClient instance for a given client ID.\n",
    "\n",
    "    Parameters:\n",
    "        cid (int): Client ID.\n",
    "\n",
    "    Returns:\n",
    "        FlowerClient: Configured FlowerClient instance.\n",
    "    \"\"\"\n",
    "    # Initialize the neural network model with specified architecture\n",
    "    net = MLP(input_size=300, hidden_size1=392, hidden_size2=392).to(DEVICE)\n",
    "    # Define file paths for training and validation data\n",
    "    train_file = f\"../No_MSC/Seed_{seed_index}/Client_{cid}_Train.csv\"\n",
    "    val_file = f\"../No_MSC/Seed_{seed_index}/Client_{cid}_Validation.csv\"\n",
    "    \n",
    "    # Load and preprocess the data\n",
    "    train_samples, train_labels, val_samples, val_labels = load_and_preprocess(train_file, val_file)\n",
    "    \n",
    "    # Convert samples and labels to PyTorch tensors\n",
    "    X_train = torch.tensor(train_samples.T, dtype=torch.float32)\n",
    "    y_train = torch.tensor(train_labels, dtype=torch.float32)\n",
    "    X_val = torch.tensor(val_samples.T, dtype=torch.float32)\n",
    "    y_val = torch.tensor(val_labels, dtype=torch.float32)\n",
    "\n",
    "    # Create TensorDatasets and DataLoaders for training and validation\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    return FlowerClient(cid, net, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77176afa-1b29-417b-bbbc-da073f82ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined validation dataset for evaluation\n",
    "def load_combined_validation(seed_index):\n",
    "    \"\"\"\n",
    "    Load and preprocess the combined validation dataset for all clients.\n",
    "\n",
    "    Parameters:\n",
    "        seed_index (int): Index of the seed for data partitioning.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: DataLoader for the combined validation dataset.\n",
    "    \"\"\"\n",
    "    # Define file path for the combined validation set\n",
    "    val_file = f\"../No_MSC/Seed_{seed_index}/Combined_Validation.csv\"\n",
    "    # Load and preprocess the combined validation data\n",
    "    _, _, val_samples, val_labels = load_and_preprocess(val_file, val_file)\n",
    "    # Convert samples and labels to PyTorch tensors\n",
    "    X_val = torch.tensor(val_samples.T, dtype=torch.float32)\n",
    "    y_val = torch.tensor(val_labels, dtype=torch.float32)\n",
    "    # Create TensorDataset and DataLoader\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c498d-e591-4309-b59e-02203330e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the aggregated model on the combined validation dataset\n",
    "def evaluate_aggregated_model(\n",
    "    server_round: int,\n",
    "    parameters: fl.common.NDArrays,\n",
    "    config: Dict[str, fl.common.Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    \"\"\"\n",
    "    Evaluate the aggregated model on the combined validation dataset.\n",
    "\n",
    "    Parameters:\n",
    "        server_round (int): Current round of federated learning.\n",
    "        parameters (fl.common.NDArrays): Aggregated model parameters from the server.\n",
    "        config (Dict[str, fl.common.Scalar]): Configuration dictionary.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Tuple[float, Dict[str, fl.common.Scalar]]]: \n",
    "        Evaluation loss and a dictionary of aggregated evaluation metrics.\n",
    "    \"\"\"\n",
    "    global best_aggregated_acc\n",
    "    # Initialize the neural network model\n",
    "    net = MLP(input_size=300, hidden_size1=392, hidden_size2=392).to(DEVICE)\n",
    "    # Load the latest parameters into the model\n",
    "    set_client_parameters(net, parameters)\n",
    "    # Evaluate the model on the combined validation set\n",
    "    loss, accuracy, precision, recall, f1 = test_client_model(net, combined_val_loader)\n",
    "    print(f\"Server-side evaluation - loss: {loss}, accuracy: {accuracy}\")\n",
    "\n",
    "    # Save the best model based on validation accuracy\n",
    "    if accuracy > best_aggregated_acc:\n",
    "        best_aggregated_acc = accuracy\n",
    "        torch.save(net.state_dict(), \"best_aggregated_model.pt\")\n",
    "        print(f\"Best aggregated model saved with accuracy {accuracy}\")\n",
    "\n",
    "    return loss, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f4d92-21a1-40aa-87c6-b310f92a0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric aggregation function using arithmetic mean\n",
    "def arithmetic_mean(metrics: List[Tuple[int, Dict[str, fl.common.Scalar]]]) -> Dict[str, fl.common.Scalar]:\n",
    "    \"\"\"\n",
    "    Compute the arithmetic mean of metrics across all clients.\n",
    "\n",
    "    Parameters:\n",
    "        metrics (List[Tuple[int, Dict[str, fl.common.Scalar]]]): \n",
    "        List of tuples containing number of samples and metric dictionaries from clients.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, fl.common.Scalar]: Aggregated metrics.\n",
    "    \"\"\"\n",
    "    # Extract accuracy and calculate mean\n",
    "    accuracies = [m[\"accuracy\"] for _, m in metrics]\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    # Extract precision and calculate mean\n",
    "    precisions = [m[\"precision\"] for _, m in metrics]\n",
    "    mean_precision = np.mean(precisions)\n",
    "    # Extract recall and calculate mean\n",
    "    recalls = [m[\"recall\"] for _, m in metrics]\n",
    "    mean_recall = np.mean(recalls)\n",
    "    # Extract F1 score and calculate mean\n",
    "    f1_scores = [m[\"f1\"] for _, m in metrics]\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    return {\"accuracy\": mean_acc, \"precision\": mean_precision, \"recall\": mean_recall, \"f1\": mean_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8fc3d-38b3-478e-9be0-5e6e057ca6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation loop for federated learning\n",
    "# Initialize the combined validation dataset loader for each seed\n",
    "combined_val_loaders = []\n",
    "\n",
    "# Store metrics for analysis\n",
    "all_metrics = []\n",
    "\n",
    "# Train and evaluate the federated model across 30 seeds\n",
    "for seed_index in range(30):\n",
    "    print(f\"Seed {seed_index+1}/30\")\n",
    "\n",
    "    # Load the combined validation dataset for the current seed\n",
    "    combined_val_loader = load_combined_validation(seed_index)\n",
    "    combined_val_loaders.append(combined_val_loader)\n",
    "\n",
    "    # Reset best aggregated accuracy for each seed\n",
    "    best_aggregated_acc = 0.0\n",
    "\n",
    "    # Define the federated learning strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Use all clients for training in each round\n",
    "        fraction_evaluate=1.0,  # Use all clients for evaluation in each round\n",
    "        min_fit_clients=5,  # Minimum number of clients required for training\n",
    "        min_evaluate_clients=5,  # Minimum number of clients required for evaluation\n",
    "        min_available_clients=NUM_CLIENTS,  # Minimum number of total clients\n",
    "        initial_parameters=fl.common.ndarrays_to_parameters(get_client_parameters(MLP(input_size=300, hidden_size1=392, hidden_size2=392))),\n",
    "        evaluate_fn=evaluate_aggregated_model,  # Evaluation function for server-side evaluation\n",
    "        evaluate_metrics_aggregation_fn=arithmetic_mean,  # Metric aggregation function\n",
    "    )\n",
    "\n",
    "    client_resources = None\n",
    "    if DEVICE.type == \"cuda\":\n",
    "        client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "    # Start the federated learning simulation\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=NUM_CLIENTS,\n",
    "        config=fl.server.ServerConfig(num_rounds=50),  # Number of training rounds\n",
    "        strategy=strategy,\n",
    "        client_resources=client_resources,\n",
    "    )\n",
    "\n",
    "    # Load and evaluate the best aggregated model for the current seed\n",
    "    aggregated_model_path = \"best_aggregated_model.pt\"\n",
    "    aggregated_model = MLP(input_size=300, hidden_size1=392, hidden_size2=392).to(DEVICE)\n",
    "    if os.path.exists(aggregated_model_path):\n",
    "        aggregated_model.load_state_dict(torch.load(aggregated_model_path))\n",
    "        loss, accuracy, precision, recall, f1 = test_client_model(aggregated_model, combined_val_loader)\n",
    "        print(f\"Aggregated model evaluation - loss: {loss}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {f1}\")\n",
    "        all_metrics.append((loss, accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088ab7c-9d2f-4929-b865-a9de9c0b3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the metrics to a DataFrame for easier plotting\n",
    "metrics_df = pd.DataFrame(all_metrics, columns=['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1'])\n",
    "\n",
    "# Plot the box plots for each metric\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Box plot for validation accuracy\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(y=metrics_df['val_accuracy'])\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Accuracy')\n",
    "mean_val = metrics_df['val_accuracy'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Box plot for validation precision\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(y=metrics_df['val_precision'])\n",
    "plt.title('Validation Precision')\n",
    "plt.xlabel('Precision')\n",
    "mean_val = metrics_df['val_precision'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Box plot for validation recall\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(y=metrics_df['val_recall'])\n",
    "plt.title('Validation Recall')\n",
    "plt.xlabel('Recall')\n",
    "mean_val = metrics_df['val_recall'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Box plot for validation F1 score\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(y=metrics_df['val_f1'])\n",
    "plt.title('Validation F1 Score')\n",
    "plt.xlabel('F1 Score')\n",
    "mean_val = metrics_df['val_f1'].mean()\n",
    "plt.scatter(0, mean_val, color='red', s=100, zorder=10)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f51924-72e3-48f5-9ef5-b09c0d888455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metrics for later comparison\n",
    "metrics_df.to_csv(\"fedMetrics/MLP_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Finished Cross-Validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
